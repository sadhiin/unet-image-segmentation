{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets.citispace import create_cityscapes_dataloaders\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from unet import UNet\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from train import train_one_epoch, validate\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "base_path = 'data'  # base path of where the cityscapes dataset is stored\n",
    "train_loader, val_loader, test_loader = create_cityscapes_dataloaders(\n",
    "    base_path=base_path,\n",
    "    batch_size=8,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of data and print sizes\n",
    "images, masks = next(iter(train_loader))\n",
    "print(f\"Image size: {images.size()}\")\n",
    "print(f\"Mask size: {masks.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Cityscapes classes from the dataset\n",
    "CITYSCAPES_CLASSES = {\n",
    "    0: 'background',\n",
    "    1: 'road',\n",
    "    2: 'sidewalk',\n",
    "    3: 'building',\n",
    "    4: 'wall',\n",
    "    5: 'fence',\n",
    "    6: 'pole',\n",
    "    7: 'traffic light',\n",
    "    8: 'traffic sign',\n",
    "    9: 'vegetation',\n",
    "    10: 'terrain',\n",
    "    11: 'sky',\n",
    "    12: 'person',\n",
    "    13: 'rider',\n",
    "    14: 'car',\n",
    "    15: 'truck',\n",
    "    16: 'bus',\n",
    "    17: 'train',\n",
    "    18: 'motorcycle',\n",
    "    19: 'bicycle',\n",
    "    255: 'ignore'  # Special ignore class\n",
    "}\n",
    "\n",
    "num_classes = 20  # Excluding ignore class (255)\n",
    "\n",
    "# Create a color palette for visualization\n",
    "COLOR_PALETTE = {\n",
    "    0: (0, 0, 0),        # background: black\n",
    "    1: (128, 64, 128),   # road: purple\n",
    "    2: (244, 35, 232),   # sidewalk: pink\n",
    "    3: (70, 70, 70),     # building: dark gray\n",
    "    4: (102, 102, 156),  # wall: dark blue-gray\n",
    "    5: (190, 153, 153),  # fence: light pink\n",
    "    6: (153, 153, 153),  # pole: gray\n",
    "    7: (250, 170, 30),   # traffic light: orange\n",
    "    8: (220, 220, 0),    # traffic sign: yellow\n",
    "    9: (107, 142, 35),   # vegetation: green\n",
    "    10: (152, 251, 152), # terrain: light green\n",
    "    11: (70, 130, 180),  # sky: blue\n",
    "    12: (220, 20, 60),   # person: red\n",
    "    13: (255, 0, 0),     # rider: bright red\n",
    "    14: (0, 0, 142),     # car: dark blue\n",
    "    15: (0, 0, 70),      # truck: darker blue\n",
    "    16: (0, 60, 100),    # bus: medium blue\n",
    "    17: (0, 80, 100),    # train: blue\n",
    "    18: (0, 0, 230),     # motorcycle: bright blue\n",
    "    19: (119, 11, 32),   # bicycle: dark red\n",
    "    255: (0, 0, 0)       # ignore: black\n",
    "}\n",
    "\n",
    "# Function to plot colormap legend\n",
    "def plot_colormap_legend():\n",
    "    num_cols = 5\n",
    "    num_rows = (len(CITYSCAPES_CLASSES) + num_cols - 1) // num_cols\n",
    "    fig, ax = plt.subplots(figsize=(15, num_rows * 2))\n",
    "\n",
    "    for idx, (class_id, class_name) in enumerate(CITYSCAPES_CLASSES.items()):\n",
    "        if class_id == 255:  # Skip ignore class in visualization\n",
    "            continue\n",
    "        row = idx // num_cols\n",
    "        col = idx % num_cols\n",
    "        color = [x/255 for x in COLOR_PALETTE[class_id]]\n",
    "        ax.add_patch(plt.Rectangle((col, -row), 1, 1, facecolor=color))\n",
    "        ax.text(col + 0.5, -row - 0.5, class_name,\n",
    "                ha='center', va='center', rotation=45)\n",
    "\n",
    "    ax.set_xlim(0, num_cols)\n",
    "    ax.set_ylim(-num_rows, 1)\n",
    "    ax.axis('off')\n",
    "    plt.title('Cityscapes Classes Color Map')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot images and masks\n",
    "def plot_predictions(images, masks, predictions=None, n_samples=4):\n",
    "    n_rows = 2 if predictions is None else 3\n",
    "    fig, axes = plt.subplots(n_rows, n_samples, figsize=(15, 5*n_rows))\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # Plot original image\n",
    "        img = images[i].permute(1, 2, 0).cpu().numpy()\n",
    "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "        img = np.clip(img, 0, 1)\n",
    "        axes[0, i].imshow(img)\n",
    "        axes[0, i].axis('off')\n",
    "        axes[0, i].set_title('Image')\n",
    "\n",
    "        # Plot ground truth mask\n",
    "        mask = masks[i].cpu().numpy()\n",
    "        colored_mask = np.zeros((*mask.shape, 3))\n",
    "        for class_id, color in COLOR_PALETTE.items():\n",
    "            colored_mask[mask == class_id] = [x/255 for x in color]\n",
    "        axes[1, i].imshow(colored_mask)\n",
    "        axes[1, i].axis('off')\n",
    "        axes[1, i].set_title('Ground Truth')\n",
    "\n",
    "        # Plot prediction if available\n",
    "        if predictions is not None:\n",
    "            pred = torch.argmax(predictions[i], dim=0).cpu().numpy()\n",
    "            colored_pred = np.zeros((*pred.shape, 3))\n",
    "            for class_id, color in COLOR_PALETTE.items():\n",
    "                colored_pred[pred == class_id] = [x/255 for x in color]\n",
    "            axes[2, i].imshow(colored_pred)\n",
    "            axes[2, i].axis('off')\n",
    "            axes[2, i].set_title('Prediction')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the colormap legend and some sample images\n",
    "plot_colormap_legend()\n",
    "plot_predictions(images, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/71998978/early-stopping-in-pytorch\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping callback similar to Keras implementation\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.0,\n",
    "        patience=5,\n",
    "        verbose=1,\n",
    "        mode='min',\n",
    "        restore_best_weights=True\n",
    "    ):\n",
    "        self.monitor = monitor\n",
    "        self.min_delta = min_delta\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.mode = mode\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "\n",
    "        self.best_weights = None\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        self.best = float('inf') if mode == 'min' else float('-inf')\n",
    "\n",
    "    def __call__(self, epoch, model, current):\n",
    "        if self.mode == 'min':\n",
    "            improved = current < (self.best - self.min_delta)\n",
    "        else:\n",
    "            improved = current > (self.best + self.min_delta)\n",
    "\n",
    "        if improved:\n",
    "            self.best = current\n",
    "            self.wait = 0\n",
    "            if self.restore_best_weights:\n",
    "                self.best_weights = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                if self.verbose > 0:\n",
    "                    print(f'Early stopping triggered at epoch {epoch}')\n",
    "                if self.restore_best_weights and self.best_weights is not None:\n",
    "                    if self.verbose > 0:\n",
    "                        print('Restoring best weights')\n",
    "                    model.load_state_dict(self.best_weights)\n",
    "                return True\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training setup\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = UNet(n_channels=3, n_classes=num_classes).to(device)\n",
    "criterion = CrossEntropyLoss(ignore_index=255)  # Ignore index for Cityscapes\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.1,\n",
    "    patience=5,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.003,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'val_iou': [],\n",
    "    'learning_rates': []\n",
    "}\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    # Training phase\n",
    "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, num_classes)\n",
    "\n",
    "    # Validation phase\n",
    "    val_loss, val_metrics = validate(model, val_loader, criterion, device, num_classes)\n",
    "\n",
    "    # Update learning rate\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Store history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_iou'].append(val_metrics['iou'])\n",
    "    history['learning_rates'].append(current_lr)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"Val IoU: {val_metrics['iou']:.4f}\")\n",
    "    print(f\"Learning Rate: {current_lr:.6f}\")\n",
    "\n",
    "    # Check early stopping\n",
    "    if early_stopping(epoch, model, val_loss):\n",
    "        print(f\"\\nTraining stopped early at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "# Save the final model and history\n",
    "torch.save(model.state_dict(), 'cityscapes_ce_final_model.pth')\n",
    "with open('cityscapes_ce_training_history.json', 'w') as f:\n",
    "    json.dump(history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['val_iou'], label='Val IoU')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('IoU')\n",
    "plt.legend()\n",
    "plt.title('Validation IoU')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model and run predictions\n",
    "import torch\n",
    "from unet import UNet\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_predictions(images, masks, predictions, n_samples=4):\n",
    "    \"\"\"\n",
    "    Plot images, ground truth masks, and predicted masks side by side\n",
    "    Args:\n",
    "        images: Tensor of shape (B, C, H, W)\n",
    "        masks: Tensor of shape (B, H, W)\n",
    "        predictions: Tensor of shape (B, C, H, W)\n",
    "        n_samples: Number of samples to display\n",
    "    \"\"\"\n",
    "    # Get predictions\n",
    "    pred_masks = torch.argmax(predictions, dim=1)\n",
    "\n",
    "    fig, axes = plt.subplots(n_samples, 3, figsize=(15, 5*n_samples))\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # Plot original image\n",
    "        img = images[i].permute(1, 2, 0).cpu().numpy()\n",
    "        # Denormalize image\n",
    "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "        img = np.clip(img, 0, 1)\n",
    "        axes[i, 0].imshow(img)\n",
    "        axes[i, 0].axis('off')\n",
    "        axes[i, 0].set_title('Image')\n",
    "\n",
    "        # Plot ground truth mask\n",
    "        mask = masks[i].cpu().numpy()\n",
    "        colored_mask = np.zeros((*mask.shape, 3))\n",
    "        for class_id, color in COLOR_PALETTE.items():\n",
    "            if class_id != 255:  # Skip ignore label\n",
    "                colored_mask[mask == class_id] = [x/255 for x in color]\n",
    "        axes[i, 1].imshow(colored_mask)\n",
    "        axes[i, 1].axis('off')\n",
    "        axes[i, 1].set_title('Ground Truth')\n",
    "\n",
    "        # Plot predicted mask\n",
    "        pred_mask = pred_masks[i].cpu().numpy()\n",
    "        colored_pred = np.zeros((*pred_mask.shape, 3))\n",
    "        for class_id, color in COLOR_PALETTE.items():\n",
    "            if class_id != 255:  # Skip ignore label\n",
    "                colored_pred[pred_mask == class_id] = [x/255 for x in color]\n",
    "        axes[i, 2].imshow(colored_pred)\n",
    "        axes[i, 2].axis('off')\n",
    "        axes[i, 2].set_title('Prediction')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def get_batch_predictions(model, data_loader, num_batches=1):\n",
    "    \"\"\"\n",
    "    Get predictions for a few batches from the data loader\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_images = []\n",
    "    all_masks = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, masks) in enumerate(data_loader):\n",
    "            if i >= num_batches:\n",
    "                break\n",
    "\n",
    "            images = images.to(device)\n",
    "            predictions = model(images)\n",
    "\n",
    "            all_images.append(images)\n",
    "            all_masks.append(masks)\n",
    "            all_predictions.append(predictions)\n",
    "\n",
    "    return (torch.cat(all_images, 0),\n",
    "            torch.cat(all_masks, 0),\n",
    "            torch.cat(all_predictions, 0))\n",
    "\n",
    "# Load the best model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "loaded_model = UNet(n_channels=3, n_classes=num_classes).to(device)\n",
    "loaded_model.load_state_dict(torch.load('cityscapes_ce_final_model.pth'))\n",
    "loaded_model.eval()\n",
    "\n",
    "# Get predictions for a few test batches\n",
    "test_images, test_masks, test_predictions = get_batch_predictions(loaded_model, test_loader, num_batches=1)\n",
    "\n",
    "# Plot the results\n",
    "plot_predictions(test_images, test_masks, test_predictions, n_samples=4)\n",
    "\n",
    "# Calculate and print metrics for the test set\n",
    "criterion = CrossEntropyLoss(ignore_index=255)\n",
    "test_loss, test_metrics = validate(loaded_model, test_loader, criterion, device, num_classes)\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "print(f\"Loss: {test_loss:.4f}\")\n",
    "print(f\"IoU: {test_metrics['iou']:.4f}\")\n",
    "print(f\"Dice Score: {test_metrics['dice']:.4f}\")\n",
    "print(f\"Precision: {test_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {test_metrics['recall']:.4f}\")\n",
    "print(f\"F1 Score: {test_metrics['f1_score']:.4f}\")\n",
    "\n",
    "# Print per-class IoU scores\n",
    "print(\"\\nPer-class IoU scores:\")\n",
    "for class_id, class_name in CITYSCAPES_CLASSES.items():\n",
    "    if class_id != 255:  # Skip ignore class\n",
    "        iou_key = f'class_{class_id}_iou'\n",
    "        if iou_key in test_metrics:\n",
    "            print(f\"{class_name}: {test_metrics[iou_key]:.4f}\")\n",
    "\n",
    "# Optional: Create a confusion matrix visualization\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(metrics):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    conf_matrix = metrics['confusion_matrix']\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
