{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets.pascal_voc import create_voc_dataloaders, VOC_CLASSES, VOC_COLORMAP\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from unet import UNet\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from train import train_one_epoch, validate\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'data'  # base path of where the Pascal VOC dataset is stored\n",
    "train_loader, val_loader, test_loader = create_voc_dataloaders(\n",
    "    base_path=base_path,\n",
    "    batch_size=8,\n",
    "    num_workers=4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, masks = next(iter(train_loader))\n",
    "print(f\"Image size: {images.size()}\")\n",
    "print(f\"Mask size: {masks.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for training\n",
    "num_classes = len(VOC_CLASSES)  # 21 classes (20 + background)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Create color palette dictionary from VOC_COLORMAP\n",
    "COLOR_PALETTE = {i: tuple(color) for i, color in enumerate(VOC_COLORMAP)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a colormap legend\n",
    "def create_colormap_legend(figsize=(15, 2)):\n",
    "    \"\"\"Create a legend showing the Pascal VOC classes and their corresponding colors\"\"\"\n",
    "    n_classes = len(VOC_CLASSES)\n",
    "    n_cols = 7  # Number of columns in the legend\n",
    "    n_rows = (n_classes + n_cols - 1) // n_cols  # Calculate required number of rows\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i, (class_name, color) in enumerate(zip(VOC_CLASSES, VOC_COLORMAP)):\n",
    "        row = i // n_cols\n",
    "        col = i % n_cols\n",
    "\n",
    "        # Create a small colored rectangle for each class\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        plt.fill([0, 1, 1, 0], [0, 0, 1, 1], color=[x/255 for x in color])\n",
    "        plt.axis('off')\n",
    "        plt.title(class_name, fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Function to plot images and masks\n",
    "def plot_sample(image, mask, prediction=None):\n",
    "    \"\"\"\n",
    "    Plot the image, ground truth mask, and prediction (if provided)\n",
    "    Args:\n",
    "        image: Tensor of shape (C, H, W)\n",
    "        mask: Tensor of shape (H, W)\n",
    "        prediction: Optional tensor of shape (C, H, W)\n",
    "    \"\"\"\n",
    "    n_subplots = 3 if prediction is not None else 2\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Plot original image\n",
    "    plt.subplot(1, n_subplots, 1)\n",
    "    img = image.permute(1, 2, 0).cpu().numpy()\n",
    "    # Denormalize image\n",
    "    img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "    img = np.clip(img, 0, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('Image')\n",
    "\n",
    "    # Plot ground truth mask\n",
    "    plt.subplot(1, n_subplots, 2)\n",
    "    mask_colored = np.zeros((*mask.shape, 3))\n",
    "    mask_np = mask.cpu().numpy()\n",
    "    for class_idx, color in enumerate(VOC_COLORMAP):\n",
    "        mask_colored[mask_np == class_idx] = [x/255 for x in color]\n",
    "    plt.imshow(mask_colored)\n",
    "    plt.axis('off')\n",
    "    plt.title('Ground Truth')\n",
    "\n",
    "    # Plot prediction if provided\n",
    "    if prediction is not None:\n",
    "        plt.subplot(1, n_subplots, 3)\n",
    "        pred = torch.argmax(prediction, dim=0).cpu().numpy()\n",
    "        pred_colored = np.zeros((*pred.shape, 3))\n",
    "        for class_idx, color in enumerate(VOC_COLORMAP):\n",
    "            pred_colored[pred == class_idx] = [x/255 for x in color]\n",
    "        plt.imshow(pred_colored)\n",
    "        plt.axis('off')\n",
    "        plt.title('Prediction')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Function to plot batch of samples\n",
    "def plot_batch_samples(images, masks, predictions=None, num_samples=4):\n",
    "    \"\"\"\n",
    "    Plot a batch of samples\n",
    "    Args:\n",
    "        images: Tensor of shape (B, C, H, W)\n",
    "        masks: Tensor of shape (B, H, W)\n",
    "        predictions: Optional tensor of shape (B, C, H, W)\n",
    "        num_samples: Number of samples to plot\n",
    "    \"\"\"\n",
    "    num_samples = min(num_samples, len(images))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        if predictions is not None:\n",
    "            plot_sample(images[i], masks[i], predictions[i])\n",
    "        else:\n",
    "            plot_sample(images[i], masks[i])\n",
    "        plt.show()\n",
    "\n",
    "# Display the colormap legend\n",
    "print(\"Pascal VOC Classes and Colors:\")\n",
    "create_colormap_legend()\n",
    "\n",
    "# Get a batch of samples and visualize them\n",
    "images, masks = next(iter(train_loader))\n",
    "print(\"\\nExample Training Samples:\")\n",
    "plot_batch_samples(images, masks, num_samples=2)\n",
    "\n",
    "# Example usage during training/validation:\n",
    "\"\"\"\n",
    "# During training loop:\n",
    "with torch.no_grad():\n",
    "    val_images, val_masks = next(iter(val_loader))\n",
    "    val_images = val_images.to(device)\n",
    "    predictions = model(val_images)\n",
    "\n",
    "    print(\"\\nValidation Samples with Predictions:\")\n",
    "    plot_batch_samples(val_images, val_masks, predictions, num_samples=2)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping callback similar to Keras implementation\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.0,\n",
    "        patience=5,\n",
    "        verbose=1,\n",
    "        mode='min',\n",
    "        restore_best_weights=True\n",
    "    ):\n",
    "        self.monitor = monitor\n",
    "        self.min_delta = min_delta\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.mode = mode\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "\n",
    "        self.best_weights = None\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        self.best = float('inf') if mode == 'min' else float('-inf')\n",
    "\n",
    "    def __call__(self, epoch, model, current):\n",
    "        if self.mode == 'min':\n",
    "            improved = current < (self.best - self.min_delta)\n",
    "        else:\n",
    "            improved = current > (self.best + self.min_delta)\n",
    "\n",
    "        if improved:\n",
    "            self.best = current\n",
    "            self.wait = 0\n",
    "            if self.restore_best_weights:\n",
    "                self.best_weights = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                if self.verbose > 0:\n",
    "                    print(f'Early stopping triggered at epoch {epoch}')\n",
    "                if self.restore_best_weights and self.best_weights is not None:\n",
    "                    if self.verbose > 0:\n",
    "                        print('Restoring best weights')\n",
    "                    model.load_state_dict(self.best_weights)\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(n_channels=3, n_classes=num_classes).to(device)\n",
    "criterion = CrossEntropyLoss(ignore_index=255)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.1,\n",
    "    patience=5,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.003,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'val_iou': [],\n",
    "    'learning_rates': []\n",
    "}\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    # Training phase\n",
    "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, num_classes)\n",
    "\n",
    "    # Validation phase\n",
    "    val_loss, val_metrics = validate(model, val_loader, criterion, device, num_classes)\n",
    "\n",
    "    # Update learning rate\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Store history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_iou'].append(val_metrics['iou'])\n",
    "    history['learning_rates'].append(current_lr)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"Val IoU: {val_metrics['iou']:.4f}\")\n",
    "    print(f\"Learning Rate: {current_lr:.6f}\")\n",
    "\n",
    "    # Print per-class IoU\n",
    "    print(\"\\nPer-class IoU:\")\n",
    "    for cls_idx, cls_name in enumerate(VOC_CLASSES):\n",
    "        iou_key = f'class_{cls_idx}_iou'\n",
    "        if iou_key in val_metrics:\n",
    "            print(f\"{cls_name}: {val_metrics[iou_key]:.4f}\")\n",
    "\n",
    "    # Check early stopping\n",
    "    if early_stopping(epoch, model, val_loss):\n",
    "        print(f\"\\nTraining stopped early at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "# Save the final model and history\n",
    "torch.save(model.state_dict(), 'pascal_voc_ce_final_model.pth')\n",
    "with open('pascal_voc_ce_training_history.json', 'w') as f:\n",
    "    json.dump(history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['val_iou'], label='Val IoU')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('IoU')\n",
    "plt.legend()\n",
    "plt.title('Validation IoU')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model and run predictions\n",
    "import torch\n",
    "from unet import UNet\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from train import validate\n",
    "\n",
    "def plot_predictions(images, masks, predictions, n_samples=4):\n",
    "    \"\"\"\n",
    "    Plot images, ground truth masks, and predicted masks side by side\n",
    "    Args:\n",
    "        images: Tensor of shape (B, C, H, W)\n",
    "        masks: Tensor of shape (B, H, W)\n",
    "        predictions: Tensor of shape (B, C, H, W)\n",
    "        n_samples: Number of samples to display\n",
    "    \"\"\"\n",
    "    # Get predictions\n",
    "    pred_masks = torch.argmax(predictions, dim=1)\n",
    "\n",
    "    fig, axes = plt.subplots(n_samples, 3, figsize=(15, 5*n_samples))\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # Plot original image\n",
    "        img = images[i].permute(1, 2, 0).cpu().numpy()\n",
    "        # Denormalize image\n",
    "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "        img = np.clip(img, 0, 1)\n",
    "        axes[i, 0].imshow(img)\n",
    "        axes[i, 0].axis('off')\n",
    "        axes[i, 0].set_title('Image')\n",
    "\n",
    "        # Plot ground truth mask\n",
    "        mask = masks[i].cpu().numpy()\n",
    "        mask_colored = np.zeros((*mask.shape, 3))\n",
    "        for class_idx, color in enumerate(VOC_COLORMAP):\n",
    "            mask_colored[mask == class_idx] = [x/255 for x in color]\n",
    "        axes[i, 1].imshow(mask_colored)\n",
    "        axes[i, 1].axis('off')\n",
    "        axes[i, 1].set_title('Ground Truth')\n",
    "\n",
    "        # Plot predicted mask\n",
    "        pred_mask = pred_masks[i].cpu().numpy()\n",
    "        pred_colored = np.zeros((*pred_mask.shape, 3))\n",
    "        for class_idx, color in enumerate(VOC_COLORMAP):\n",
    "            pred_colored[pred_mask == class_idx] = [x/255 for x in color]\n",
    "        axes[i, 2].imshow(pred_colored)\n",
    "        axes[i, 2].axis('off')\n",
    "        axes[i, 2].set_title('Prediction')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def get_batch_predictions(model, data_loader, num_batches=1):\n",
    "    \"\"\"\n",
    "    Get predictions for a few batches from the data loader\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_images = []\n",
    "    all_masks = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, masks) in enumerate(data_loader):\n",
    "            if i >= num_batches:\n",
    "                break\n",
    "\n",
    "            images = images.to(device)\n",
    "            predictions = model(images)\n",
    "\n",
    "            all_images.append(images)\n",
    "            all_masks.append(masks)\n",
    "            all_predictions.append(predictions)\n",
    "\n",
    "    return (torch.cat(all_images, 0),\n",
    "            torch.cat(all_masks, 0),\n",
    "            torch.cat(all_predictions, 0))\n",
    "\n",
    "# Load the best model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "num_classes = len(VOC_CLASSES)  # 21 classes (20 + background)\n",
    "loaded_model = UNet(n_channels=3, n_classes=num_classes).to(device)\n",
    "loaded_model.load_state_dict(torch.load('pascal_voc_ce_final_model.pth'))\n",
    "loaded_model.eval()\n",
    "\n",
    "# Get predictions for a few test batches\n",
    "test_images, test_masks, test_predictions = get_batch_predictions(loaded_model, test_loader, num_batches=1)\n",
    "\n",
    "# Plot the results\n",
    "plot_predictions(test_images, test_masks, test_predictions, n_samples=4)\n",
    "\n",
    "# Calculate and print metrics for the test set\n",
    "criterion = CrossEntropyLoss()\n",
    "test_loss, test_metrics = validate(loaded_model, test_loader, criterion, device, num_classes)\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "print(f\"Loss: {test_loss:.4f}\")\n",
    "print(f\"IoU: {test_metrics['iou']:.4f}\")\n",
    "print(f\"Dice Score: {test_metrics['dice']:.4f}\")\n",
    "print(f\"Precision: {test_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {test_metrics['recall']:.4f}\")\n",
    "print(f\"F1 Score: {test_metrics['f1_score']:.4f}\")\n",
    "\n",
    "# Print per-class IoU scores\n",
    "print(\"\\nPer-class IoU scores:\")\n",
    "for class_idx, class_name in enumerate(VOC_CLASSES):\n",
    "    iou_key = f'class_{class_idx}_iou'\n",
    "    if iou_key in test_metrics:\n",
    "        print(f\"{class_name}: {test_metrics[iou_key]:.4f}\")\n",
    "\n",
    "# Optional: Create a confusion matrix visualization\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(metrics):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    conf_matrix = metrics['confusion_matrix']\n",
    "\n",
    "    # Create labels for classes\n",
    "    labels = VOC_CLASSES\n",
    "\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=labels, yticklabels=labels)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(test_metrics)\n",
    "\n",
    "# Create legend for class colors\n",
    "print(\"\\nPascal VOC Classes and Colors:\")\n",
    "create_colormap_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
